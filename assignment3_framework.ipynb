{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 1        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 4        4.0  0.0  5.0  0.0  0.0  3.0  4.0  2.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      4.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 296      4.0  0.0  4.0  0.0  0.0  4.0  3.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 297      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 299      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        3.0  0.0  4.0  0.0  0.0  3.0  2.0  2.0  0.0  5.0  ...  0.0  4.0  0.0   \n",
       " 2        0.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  ...  0.0  0.0  3.0   \n",
       " 3        0.0  4.0  4.0  4.0  3.0  2.0  3.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  4.0  4.0  0.0  5.0  ...  3.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  5.0  0.0  0.0  0.0  4.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " 197      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  2.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  5.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3"
   },
   "outputs": [],
   "source": [
    "## Put all your implementation for your solutioin in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "# finding the similarity for item - item\n",
    "item_item_sim_matrix = np.zeros((imputed_train_ds.shape[1], imputed_train_ds.shape[1]))\n",
    "\n",
    "for i, i_item_vec in enumerate(imputed_train_ds.T):\n",
    "    for j, j_item_vec in enumerate(imputed_train_ds.T):\n",
    "\n",
    "        i_mask = i_item_vec > 0\n",
    "        j_mask = j_item_vec > 0\n",
    "\n",
    "        corrated_index = np.intersect1d(np.where(i_mask), np.where(j_mask))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        i_item_mean = np.sum(i_item_vec) / (np.sum(np.clip(i_item_vec, 0, 1)) + EPSILON)\n",
    "        j_item_mean = np.sum(j_item_vec) / (np.sum(np.clip(j_item_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        i_mean_item_sub = i_item_vec[corrated_index] - i_item_mean\n",
    "        j_mean_item_sub = j_item_vec[corrated_index] - j_item_mean\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(i_mean_item_sub)\n",
    "        r_uj_sub_rj_sq = np.square(j_mean_item_sub)\n",
    "\n",
    "        avg_sqrt_first_item = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        avg_sqrt_second_item = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(i_mean_item_sub * j_mean_item_sub) / (avg_sqrt_first_item * avg_sqrt_second_item + EPSILON)\n",
    "\n",
    "        simlarity_weight = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "        \n",
    "        \n",
    "        item_item_sim_matrix[i][j] = simlarity_weight\n",
    "\n",
    "        \n",
    "\n",
    "#finding similarity for users\n",
    "\n",
    "\n",
    "user_user_sim_matrix = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
    "\n",
    "for i, i_user_vec in enumerate(imputed_train_ds):\n",
    "    for j, j_user_vec in enumerate(imputed_train_ds):\n",
    "\n",
    "        i_mask = i_user_vec > 0\n",
    "        j_mask = j_user_vec > 0\n",
    "\n",
    "        corrated_index = np.intersect1d(np.where(i_mask), np.where(j_mask))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        i_user_mean = np.sum(i_user_vec) / (np.sum(np.clip(i_user_vec, 0, 1)) + EPSILON)\n",
    "        j_user_mean = np.sum(j_user_vec) / (np.sum(np.clip(j_user_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        i_mean_user_sub = i_user_vec[corrated_index] - i_user_mean\n",
    "        j_mean_user_sub = j_user_vec[corrated_index] - j_user_mean\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(i_mean_user_sub)\n",
    "        r_uj_sub_rj_sq = np.square(j_mean_user_sub)\n",
    "\n",
    "        avg_sqrt_first_user = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        avg_sqrt_second_user = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(i_mean_user_sub * j_mean_user_sub) / (avg_sqrt_first_user * avg_sqrt_second_user + EPSILON)\n",
    "\n",
    "        simlarity_weight = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "        \n",
    "        user_user_sim_matrix[i][j] =  simlarity_weight\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "np_predictions = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[1]))\n",
    "\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(imputed_train_ds):\n",
    "    \n",
    "         \n",
    "    #user-item\n",
    "\n",
    "        #find the similar users\n",
    "        sim_user_ids = np.argsort(user_user_sim_matrix[i])\n",
    "        #similarity co-efficent of values of user \n",
    "        sim_value = []\n",
    "        sim_user_ids_1 = []\n",
    "        for m in range(len(user_user_sim_matrix[i][sim_user_ids])):\n",
    "\n",
    "            if user_user_sim_matrix[i][sim_user_ids][m] > ITA and user_user_sim_matrix[i][sim_user_ids][m] < 1:\n",
    "\n",
    "                sim_value.append(user_user_sim_matrix[i][sim_user_ids][m])\n",
    "                sim_user_ids_1.append(sim_user_ids[m])\n",
    "        sim_value = np.array(sim_value)\n",
    "        sim_user_ids_1 = np.array(sim_user_ids_1)\n",
    "    \n",
    "    #item-user\n",
    "        \n",
    "        sim_item_ids = np.argsort(item_item_sim_matrix[j])\n",
    "        sim_item_value =[]\n",
    "        sim_item_ids_1=[]\n",
    "        \n",
    "        for n in range(len(item_item_sim_matrix[j][sim_item_ids])):\n",
    "                      \n",
    "            if item_item_sim_matrix[j][sim_item_ids][n] > THETA and item_item_sim_matrix[j][sim_item_ids][n] < 1:\n",
    "                \n",
    "                sim_item_value.append(item_item_sim_matrix[j][sim_item_ids][n])\n",
    "                sim_item_ids_1.append(sim_item_ids[n])\n",
    "        \n",
    "        sim_item_value = np.array(sim_item_value)\n",
    "        sim_item_ids_1 = np.array(sim_item_ids_1)\n",
    "        \n",
    "        if (sim_item_value.size > 0) and (sim_value.size == 0):\n",
    "\n",
    "            \n",
    "            sim_items = imputed_train_ds.T[sim_item_ids_1]\n",
    "            item_mean = np.sum(imputed_train_ds.T[j]) / (np.sum(np.clip(imputed_train_ds.T[j], 0, 1))+EPSILON)\n",
    "            sim_item_mean = np.sum(sim_items,axis = 1) / (np.sum(np.clip(sim_items, 0 ,1),axis = 1)+EPSILON)\n",
    "            mask_rated_i = sim_items[:,i] >0\n",
    "            \n",
    "            sim_r_sum_mean = sim_item_value[mask_rated_i] * (sim_items[mask_rated_i, i] - sim_item_mean[mask_rated_i])\n",
    "\n",
    "            np_predictions[i][j] = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_item_value[mask_rated_i]) + EPSILON)\n",
    "            np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "            \n",
    "            if imputed_train_ds[i][j] == 0:\n",
    "                imputed_train_ds[i][j] = np_predictions[i][j]\n",
    "\n",
    "            \n",
    "        elif (sim_value.size > 0) and (sim_item_value.size == 0):\n",
    "\n",
    "          \n",
    "            sim_users = imputed_train_ds[sim_user_ids_1]\n",
    "            \n",
    "            user_mean = np.sum(imputed_train_ds[i]) / (np.sum(np.clip(imputed_train_ds[i], 0, 1))+EPSILON)\n",
    "            sim_user_mean = np.sum(sim_users,axis = 1) / (np.sum(np.clip(sim_users, 0 ,1),axis = 1)+EPSILON)\n",
    "            mask_rated_j = sim_users[:,j] >0\n",
    "\n",
    "            sim_r_sum_mean = sim_value[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "\n",
    "            np_predictions[i][j] = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_value[mask_rated_j]) + EPSILON)\n",
    "            np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "            \n",
    "            if imputed_train_ds[i][j] == 0:\n",
    "                imputed_train_ds[i][j] = np_predictions[i][j]\n",
    "            \n",
    "            \n",
    "        elif(sim_value.size > 0) and (sim_item_value.size > 0):\n",
    "\n",
    "            sim_items = imputed_train_ds.T[sim_item_ids_1]\n",
    "            item_mean = np.sum(imputed_train_ds.T[j]) / (np.sum(np.clip(imputed_train_ds.T[j], 0, 1))+EPSILON)\n",
    "            sim_item_mean = np.sum(sim_items,axis = 1) / (np.sum(np.clip(sim_items, 0 ,1),axis = 1)+EPSILON)\n",
    "            mask_rated_i = sim_items[:,i] >0\n",
    "            \n",
    "            sim_r_sum_mean = sim_item_value[mask_rated_i] * (sim_items[mask_rated_i, i] - sim_item_mean[mask_rated_i])\n",
    "\n",
    "            item = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_item_value[mask_rated_i]) + EPSILON)\n",
    "            \n",
    "            \n",
    "            \n",
    "            sim_users = imputed_train_ds[sim_user_ids_1]\n",
    "            user_mean = np.sum(imputed_train_ds[i]) / (np.sum(np.clip(imputed_train_ds[i], 0, 1))+EPSILON)\n",
    "            sim_user_mean = np.sum(sim_users,axis = 1) / (np.sum(np.clip(sim_users, 0 ,1),axis = 1)+EPSILON)\n",
    "            mask_rated_j = sim_users[:,j] >0\n",
    "\n",
    "            sim_r_sum_mean = sim_value[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "\n",
    "            user = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_value[mask_rated_j]) + EPSILON)\n",
    "            \n",
    "            np_predictions[i][j] = ((LAMBDA)*(user) )+ ((1 - LAMBDA)*(item))\n",
    "            \n",
    "            np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "            \n",
    "            if imputed_train_ds[i][j] == 0:\n",
    "                imputed_train_ds[i][j] = np_predictions[i][j]\n",
    "        else:\n",
    "            np_predictions[i][j] = 0\n",
    "            if imputed_train_ds[i][j] == 0:\n",
    "                imputed_train_ds[i][j] = np_predictions[i][j]\n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.829127</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.209420</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.439398</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.686601</td>\n",
       "      <td>3.293528</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.490373</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.738610</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.208256</td>\n",
       "      <td>3.735092</td>\n",
       "      <td>3.447461</td>\n",
       "      <td>3.223310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.091690</td>\n",
       "      <td>4.004791</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.847684</td>\n",
       "      <td>4.052298</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.828374</td>\n",
       "      <td>3.946646</td>\n",
       "      <td>...</td>\n",
       "      <td>3.831194</td>\n",
       "      <td>3.761851</td>\n",
       "      <td>4.050723</td>\n",
       "      <td>3.933634</td>\n",
       "      <td>3.695716</td>\n",
       "      <td>3.656909</td>\n",
       "      <td>3.659541</td>\n",
       "      <td>4.033253</td>\n",
       "      <td>3.648585</td>\n",
       "      <td>3.790726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.540059</td>\n",
       "      <td>4.056860</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.025909</td>\n",
       "      <td>3.785061</td>\n",
       "      <td>3.987944</td>\n",
       "      <td>3.883311</td>\n",
       "      <td>3.670460</td>\n",
       "      <td>3.881337</td>\n",
       "      <td>...</td>\n",
       "      <td>3.783769</td>\n",
       "      <td>3.679259</td>\n",
       "      <td>3.767874</td>\n",
       "      <td>3.871586</td>\n",
       "      <td>3.622118</td>\n",
       "      <td>3.619349</td>\n",
       "      <td>3.469084</td>\n",
       "      <td>3.805717</td>\n",
       "      <td>3.592746</td>\n",
       "      <td>3.643307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.040227</td>\n",
       "      <td>4.137668</td>\n",
       "      <td>4.072213</td>\n",
       "      <td>3.959556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.801418</td>\n",
       "      <td>4.002911</td>\n",
       "      <td>3.770500</td>\n",
       "      <td>3.688766</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.764434</td>\n",
       "      <td>3.700436</td>\n",
       "      <td>3.958327</td>\n",
       "      <td>3.879275</td>\n",
       "      <td>3.649267</td>\n",
       "      <td>3.686861</td>\n",
       "      <td>3.478475</td>\n",
       "      <td>3.956503</td>\n",
       "      <td>3.606777</td>\n",
       "      <td>3.805198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.215861</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.547428</td>\n",
       "      <td>3.330157</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.396593</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.216427</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.656549</td>\n",
       "      <td>3.539524</td>\n",
       "      <td>3.020071</td>\n",
       "      <td>2.857111</td>\n",
       "      <td>3.067230</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.272274</td>\n",
       "      <td>3.056421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.655659</td>\n",
       "      <td>4.676927</td>\n",
       "      <td>2.623083</td>\n",
       "      <td>3.390411</td>\n",
       "      <td>2.505079</td>\n",
       "      <td>4.238273</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.752715</td>\n",
       "      <td>3.914452</td>\n",
       "      <td>...</td>\n",
       "      <td>3.782010</td>\n",
       "      <td>3.226528</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.791034</td>\n",
       "      <td>2.729840</td>\n",
       "      <td>3.561633</td>\n",
       "      <td>2.928846</td>\n",
       "      <td>3.978315</td>\n",
       "      <td>3.413422</td>\n",
       "      <td>3.165319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.575754</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.814560</td>\n",
       "      <td>3.497203</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.689859</td>\n",
       "      <td>3.783807</td>\n",
       "      <td>...</td>\n",
       "      <td>3.759570</td>\n",
       "      <td>3.696846</td>\n",
       "      <td>3.773099</td>\n",
       "      <td>3.769784</td>\n",
       "      <td>3.639692</td>\n",
       "      <td>3.775224</td>\n",
       "      <td>3.666880</td>\n",
       "      <td>3.744009</td>\n",
       "      <td>3.678147</td>\n",
       "      <td>3.692321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.228612</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.748918</td>\n",
       "      <td>3.650731</td>\n",
       "      <td>3.945513</td>\n",
       "      <td>3.751572</td>\n",
       "      <td>3.444896</td>\n",
       "      <td>3.362871</td>\n",
       "      <td>3.604954</td>\n",
       "      <td>...</td>\n",
       "      <td>3.513165</td>\n",
       "      <td>3.378540</td>\n",
       "      <td>3.900349</td>\n",
       "      <td>3.663103</td>\n",
       "      <td>3.230792</td>\n",
       "      <td>3.442364</td>\n",
       "      <td>3.246073</td>\n",
       "      <td>3.561631</td>\n",
       "      <td>3.494416</td>\n",
       "      <td>3.527495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.154619</td>\n",
       "      <td>2.796488</td>\n",
       "      <td>3.331390</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.101568</td>\n",
       "      <td>3.067835</td>\n",
       "      <td>3.256615</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.314203</td>\n",
       "      <td>3.386628</td>\n",
       "      <td>...</td>\n",
       "      <td>1.908426</td>\n",
       "      <td>3.130069</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.387452</td>\n",
       "      <td>3.169766</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.058678</td>\n",
       "      <td>3.300555</td>\n",
       "      <td>3.231282</td>\n",
       "      <td>3.083397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3.895765</td>\n",
       "      <td>3.686860</td>\n",
       "      <td>4.321394</td>\n",
       "      <td>3.748343</td>\n",
       "      <td>3.289484</td>\n",
       "      <td>3.587136</td>\n",
       "      <td>3.739843</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.478814</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.603346</td>\n",
       "      <td>3.746161</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.623300</td>\n",
       "      <td>3.595354</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.757881</td>\n",
       "      <td>3.552076</td>\n",
       "      <td>3.598249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.829127  2.000000  4.209420  4.000000  3.439398  4.000000  4.000000   \n",
       "1    4.091690  4.004791  4.000000  4.000000  4.000000  3.847684  4.052298   \n",
       "2    4.000000  3.540059  4.056860  2.000000  4.025909  3.785061  3.987944   \n",
       "3    4.040227  4.137668  4.072213  3.959556  5.000000  3.801418  4.002911   \n",
       "4    4.000000  3.215861  5.000000  3.547428  3.330157  3.000000  4.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  4.000000  3.655659  4.676927  2.623083  3.390411  2.505079  4.238273   \n",
       "296  4.000000  3.575754  4.000000  3.814560  3.497203  4.000000  3.000000   \n",
       "297  4.000000  3.228612  3.000000  3.748918  3.650731  3.945513  3.751572   \n",
       "298  4.154619  2.796488  3.331390  3.000000  3.101568  3.067835  3.256615   \n",
       "299  3.895765  3.686860  4.321394  3.748343  3.289484  3.587136  3.739843   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    3.686601  3.293528  2.000000  ...  3.490373  4.000000  4.000000   \n",
       "1    4.000000  3.828374  3.946646  ...  3.831194  3.761851  4.050723   \n",
       "2    3.883311  3.670460  3.881337  ...  3.783769  3.679259  3.767874   \n",
       "3    3.770500  3.688766  4.000000  ...  3.764434  3.700436  3.958327   \n",
       "4    2.000000  3.396593  2.000000  ...  3.216427  2.000000  3.656549   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  4.000000  3.752715  3.914452  ...  3.782010  3.226528  4.000000   \n",
       "296  4.000000  3.689859  3.783807  ...  3.759570  3.696846  3.773099   \n",
       "297  3.444896  3.362871  3.604954  ...  3.513165  3.378540  3.900349   \n",
       "298  4.000000  3.314203  3.386628  ...  1.908426  3.130069  5.000000   \n",
       "299  3.000000  3.000000  3.478814  ...  4.000000  3.603346  3.746161   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.738610  3.000000  3.000000  3.208256  3.735092  3.447461  3.223310  \n",
       "1    3.933634  3.695716  3.656909  3.659541  4.033253  3.648585  3.790726  \n",
       "2    3.871586  3.622118  3.619349  3.469084  3.805717  3.592746  3.643307  \n",
       "3    3.879275  3.649267  3.686861  3.478475  3.956503  3.606777  3.805198  \n",
       "4    3.539524  3.020071  2.857111  3.067230  4.000000  3.272274  3.056421  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  3.791034  2.729840  3.561633  2.928846  3.978315  3.413422  3.165319  \n",
       "296  3.769784  3.639692  3.775224  3.666880  3.744009  3.678147  3.692321  \n",
       "297  3.663103  3.230792  3.442364  3.246073  3.561631  3.494416  3.527495  \n",
       "298  3.387452  3.169766  3.000000  3.058678  3.300555  3.231282  3.083397  \n",
       "299  5.000000  3.623300  3.595354  3.000000  3.757881  3.552076  3.598249  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04814179, -0.29222158, -0.16368312, ...,  0.08154789,\n",
       "         0.39953132, -0.17553639],\n",
       "       [-0.13176887,  0.03146049, -0.17023023, ...,  0.37312952,\n",
       "         0.39567131,  0.28478696],\n",
       "       [ 0.04593563,  0.0839935 , -0.16844836, ..., -0.22212957,\n",
       "        -0.04784197,  0.15393656],\n",
       "       ...,\n",
       "       [ 0.20204093,  0.38926563, -0.20212429, ..., -0.06731283,\n",
       "        -0.14874741,  0.41765361],\n",
       "       [ 0.1700147 ,  0.38987035, -0.09248602, ...,  0.02744657,\n",
       "         0.15250432, -0.06140499],\n",
       "       [ 0.12481482,  0.28484048,  0.24550622, ...,  0.48839251,\n",
       "         0.45195605,  0.1431662 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 3.35387411,\n",
       "        0.        ],\n",
       "       [3.53987511, 0.        , 3.46931344, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 3.40495677, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 2.90881134, ..., 0.        , 2.43176473,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 3.33789196, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7671841127059978, RMSE: 0.9801677612584818\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03281917435856474"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8000032870645626 - MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04497231890433939"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0251400801628212 - RMSE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
